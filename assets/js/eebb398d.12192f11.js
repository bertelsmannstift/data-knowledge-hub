"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8113],{6990:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>l,toc:()=>d});var i=n(4848),s=n(8453);const r={title:"Data Collection on YouTube",sidebar_position:2},o="Data Collection on YouTube",l={id:"data-collection/03_00_platform-specific guidelines/03_00_data-collection_youtube",title:"Data Collection on YouTube",description:"<AuthorCard",source:"@site/docs/03_data-collection/03_00_platform-specific guidelines/03_00_data-collection_youtube.mdx",sourceDirName:"03_data-collection/03_00_platform-specific guidelines",slug:"/data-collection/03_00_platform-specific guidelines/03_00_data-collection_youtube",permalink:"/docs/data-collection/03_00_platform-specific guidelines/03_00_data-collection_youtube",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{title:"Data Collection on YouTube",sidebar_position:2},sidebar:"docs",previous:{title:"Twitter Rules",permalink:"/docs/data-collection/03_00_platform-specific guidelines/twitter/twitter-rules"},next:{title:"Data Collection on Rumble",permalink:"/docs/data-collection/03_00_platform-specific guidelines/03_01_data-collection_rumble"}},a={},d=[{value:"Disinformation on video platforms",id:"disinformation-on-video-platforms",level:2},{value:"What you will learn in this chapter",id:"what-you-will-learn-in-this-chapter",level:3},{value:"Authentication",id:"authentication",level:3},{value:"Basic Setup",id:"basic-setup",level:2},{value:"Construction of a single query",id:"construction-of-a-single-query",level:2},{value:"Data collection methods: Search",id:"data-collection-methods-search",level:2},{value:"Data collection methods: Video information",id:"data-collection-methods-video-information",level:2},{value:"Data collection methods: Comments",id:"data-collection-methods-comments",level:2},{value:"Data collection methods: Channels",id:"data-collection-methods-channels",level:2},{value:"References",id:"references",level:2}];function c(e){const t={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components},{AuthorCard:r,LanguageChip:o,LastUpdatedByChip:l,LevelChip:a,PlatformChip:d}=t;return r||u("AuthorCard",!0),o||u("LanguageChip",!0),l||u("LastUpdatedByChip",!0),a||u("LevelChip",!0),d||u("PlatformChip",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"data-collection-on-youtube",children:"Data Collection on YouTube"})}),"\n",(0,i.jsx)(a,{level:"Beginner"}),"\n",(0,i.jsx)(d,{platform:"YouTube"}),"\n",(0,i.jsx)(o,{lang:"Python"}),"\n",(0,i.jsx)(r,{name:"Richard Schwenn",avatar:"RS",avatarSrc:n(2057).A,position:"polisphere",website:"https://www.polisphere.eu/de/",linkedin:"https://www.linkedin.com/in/richard-schwenn-6b787623a/"}),"\n",(0,i.jsx)(l,{authorOriginal:"Richard Schwenn",createdOn:"05.06.2025"}),"\n",(0,i.jsx)(t.h2,{id:"disinformation-on-video-platforms",children:"Disinformation on video platforms"}),"\n",(0,i.jsx)(t.p,{children:"With the visual turn on social media and the growing importance of audio-visual platforms as information spaces, researchers have long acknowledged YouTube\u2019s central role as a conduit of disinformation, conspiracy and extremist discourse (Allgaier, 2019; Kn\xfcpfer et al., 2023)."}),"\n",(0,i.jsx)(t.p,{children:"In the rapidly developing nexus of disinformation and Artificial Intelligence (AI), YouTube already hosts a variety of manipulative synthetic content, exemplified by recent discoveries of Spanish-speaking, anti-European content disseminated massively by disinformation networks (Maldida.es, 2025)."}),"\n",(0,i.jsx)(t.p,{children:"This underlines the need for researchers to closely monitor activities on the platform and collect large-scale data for analyses. Fortunately, as YouTube has been the dominant video platform for over a decade now and has long provided access to many features through different APIs, there are lots of brilliant resources out there to help collecting different types of data from YouTube (Richardson & Flannery O\u2019Connor, 2023)."}),"\n",(0,i.jsx)(t.h3,{id:"what-you-will-learn-in-this-chapter",children:"What you will learn in this chapter"}),"\n",(0,i.jsx)(t.p,{children:"This tutorial focuses on three main data collection methods, equipping you to monitor:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["the prevalence of topic specific videos through ",(0,i.jsx)(t.strong,{children:"search queries"}),";"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Comment sections"})," under specific videos;"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"YouTube channels"}),", their statistics and video output."]}),"\n"]}),"\n",(0,i.jsx)(t.h3,{id:"authentication",children:"Authentication"}),"\n",(0,i.jsxs)(t.p,{children:["Before getting started, make sure to have all necessary authentication requirements. Obtaining an ",(0,i.jsx)(t.strong,{children:"API key"})," or ",(0,i.jsx)(t.strong,{children:"OAuth 2.0 token"})," is the central requirement to making any valid request. However, in contrast to other platforms, there are no huge obstacles to gain access (like vetting processes for researchers). All you need is a Google account with permission to create projects on the Google Cloud Console. ",(0,i.jsx)(t.strong,{children:"Step-by-step guides to get an API key"})," are provided in written form ",(0,i.jsx)(t.a,{href:"https://medium.com/mcd-unison/youtube-data-api-v3-in-python-tutorial-with-examples-e829a25d2ebd",children:"here"})," and in video form ",(0,i.jsx)(t.a,{href:"https://www.youtube.com/watch?v=th5_9woFJmk",children:"here"}),". For all the data collection performed in this tutorial, the ",(0,i.jsx)(t.strong,{children:"OAuth 2.0 token is not required"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["With a key in hand, it is best to follow along using a ",(0,i.jsx)(t.a,{href:"https://jupyter.org/",children:"Jupyter Notebook"})," either in your browser or any common programming environments (IDEs) like ",(0,i.jsx)(t.a,{href:"https://code.visualstudio.com/",children:"Visual Studio Code"}),"."]}),"\n",(0,i.jsx)(t.p,{children:"The tutorial guides you through as follows:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Basic setup"}),"\n",(0,i.jsx)(t.li,{children:"Construction of a single query"}),"\n",(0,i.jsxs)(t.li,{children:["Data collection methods:","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Search"}),"\n",(0,i.jsx)(t.li,{children:"Video information"}),"\n",(0,i.jsx)(t.li,{children:"Comments"}),"\n",(0,i.jsx)(t.li,{children:"Channels"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.admonition,{title:"Note",type:"hub-note",children:(0,i.jsxs)(t.p,{children:["If you want to expand your data collection beyond what is shown here, you can find the ",(0,i.jsx)(t.strong,{children:"extensive documentation"})," for this API provided by Google ",(0,i.jsx)(t.a,{href:"https://developers.google.com/youtube/v3/docs",children:"here"}),".\r\nThere is a ",(0,i.jsx)(t.strong,{children:"quota"})," for the API, with standard projects being limited to 10,000 request units per day. Google provides an overview of quota unit calculation ",(0,i.jsx)(t.a,{href:"https://developers.google.com/youtube/v3/determine_quota_cost",children:"here"}),"."]})}),"\n",(0,i.jsx)(t.h2,{id:"basic-setup",children:"Basic Setup"}),"\n",(0,i.jsx)(t.p,{children:"In our python environment, we will use the following packages, all easily installable via pip (PyPI). First, install them using the command below:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"pip install jsonlines tqdm pandas google-api-python-client\r\n#The exclamation point is used to signal to your machine that this shell command (\u201cpip install something\u201d) should be run externally\n"})}),"\n",(0,i.jsx)(t.p,{children:"Then, import them into your environment:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"import jsonlines \r\nimport json\r\nimport pandas as pd\r\nfrom datetime import datetime\r\nfrom tqdm import tqdm\r\nimport os\r\n \r\nimport googleapiclient.discovery\r\nfrom googleapiclient.discovery import build\r\nimport googleapiclient.errors\n"})}),"\n",(0,i.jsx)(t.p,{children:"Here, you insert the necessary information for the authentication:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'\r\n# You can disable OAuthlib\'s HTTPS verification when running locally.\r\n# Please *DO NOT* leave this option enabled in production.\r\nos.environ["OAUTHLIB_INSECURE_TRANSPORT"] = "1"\r\n \r\nAPI_key = "YOUR_API_KEY_HERE" ## Replace this string with your actual API key \r\nAPI_service_name = "youtube" ## Specify what Google API you want to use\r\nAPI_version = "v3" ## Specify the version \n'})}),"\n",(0,i.jsx)(t.admonition,{title:"Note",type:"hub-note",children:(0,i.jsxs)(t.p,{children:["Storing credentials like API keys or other sensitive information in plain sight is fine when running your scripts locally. However, a more secure approach is to set them up as environment variables outside your script or to use a configuration file. An easy-to-follow tutorial on the different ways to store sensitive information securely can be accessed ",(0,i.jsx)(t.a,{href:"https://saturncloud.io/blog/how-to-set-environment-variables-in-jupyter-notebooks-a-guide-for-data-scientists/",children:"here"}),"."]})}),"\n",(0,i.jsxs)(t.p,{children:["Now you can construct your ",(0,i.jsx)(t.strong,{children:"API client"}),". This object ",(0,i.jsx)(t.code,{children:"youtube"})," is how you interact with and make calls to retrieve YouTube data."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"youtube = build(API_service_name, API_version, developerKey=API_key)\n"})}),"\n",(0,i.jsx)(t.h2,{id:"construction-of-a-single-query",children:"Construction of a single query"}),"\n",(0,i.jsxs)(t.p,{children:["In essence, all YouTube data is ",(0,i.jsx)(t.strong,{children:"categorized into different resources"})," (channels, videos, playlists, thumbnails, etc.). Each resource affords different methods to retrieve data of interest but, luckily, the query structure is largely the same."]}),"\n",(0,i.jsxs)(t.p,{children:["Let us look at a ",(0,i.jsx)(t.strong,{children:"single query example"}),". We want to query the YouTube Data API for the top 50 most viewed videos related to election integrity in the weeks leading up to the US election. We use our client object to access the ",(0,i.jsx)(t.code,{children:"search()"})," resource. The ",(0,i.jsx)(t.code,{children:"list()"})," function allows us to retrieve a collection of results that match the query \u2013 this can be videos but also channels or playlists. Inside the ",(0,i.jsx)(t.code,{children:"list()"})," function, we specify some necessary and optional parameters."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'## Initial API request \r\nrequest = youtube.search().list( \r\n    part="snippet", #neccessary parameter, where snippet contains more detailed information \r\n    maxResults=50, #default value is 5, max value is 50 \r\n    publishedAfter="2024-10-01T00:00:00Z", \r\n    publishedBefore="2024-11-06T00:00:00Z", #timeframe of interest\r\n    order="viewCount", #alternative would be by \u201cdate\u201d in reverse chronological order\r\n    q="election fraud | stolen election | election lie", \r\n    #Use this \u201c|\u201d OR separator or the NOT (-) operator to further specify your keywords of interest\r\n    relevanceLanguage="en", #returns videos most relevant to the specified language \r\n    type="video" #we only want videos as results\r\n)\r\n \r\n \r\nresponse = request.execute() #Use this command to execute our API call \n'})}),"\n",(0,i.jsx)(t.p,{children:"If the request was successful, the response contains a dictionary with the following keys:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"response.keys()\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"dict_keys(['kind','etag','nextPageToken','regionCode','pageInfo','items'])\n"})}),"\n",(0,i.jsx)(t.p,{children:"The video results are stored inside items, you can see the exemplary information we retrieved for the first video here:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'response["items"][0]\n'})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"\r\n{'kind': 'youtube#searchResult',\r\n 'etag': '2PoKoFaYrW3QLMB7vec-RZEr_rM',\r\n 'id': {'kind': 'youtube#video', 'videoId': 'IPUhRjAMCTo'}, #videoId is important for later!\r\n 'snippet': {'publishedAt': '2024-10-08T03:00:17Z',\r\n  'channelId': 'UCwWhs_6x42TyRM4Wstoq8HA',\r\n  'title': 'Jon Stewart on Elon Musk, Free Speech & Trump's Election Interference Claims | The Daily Show',\r\n  'description': 'With less than a month until Election Day, Jon Stewart unpacks how Trump and his newest \"dark MAGA\" henchman, Elon Musk, ...',\r\n  'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/IPUhRjAMCTo/default.jpg',\r\n    'width': 120,\r\n    'height': 90},\r\n   'medium': {'url': 'https://i.ytimg.com/vi/IPUhRjAMCTo/mqdefault.jpg',\r\n    'width': 320,\r\n    'height': 180},\r\n   'high': {'url': 'https://i.ytimg.com/vi/IPUhRjAMCTo/hqdefault.jpg',\r\n    'width': 480,\r\n    'height': 360}},\r\n  'channelTitle': 'The Daily Show',\r\n  'liveBroadcastContent': 'none',\r\n  'publishTime': '2024-10-08T03:00:17Z'}}\r\n\n"})}),"\n",(0,i.jsx)(t.h2,{id:"data-collection-methods-search",children:"Data collection methods: Search"}),"\n",(0,i.jsxs)(t.p,{children:["While we have already successfully run a YouTube search query, in any research effort, 50 results are hardly enough to obtain meaningful insights. You can retrieve more data through the ",(0,i.jsx)(t.code,{children:"nextPageToken"}),". This is insofar important, as most APIs rely on pagination to control the amount of data access to their servers."]}),"\n",(0,i.jsxs)(t.p,{children:["If there are more results to your query, the response will include a ",(0,i.jsx)(t.code,{children:"nextPageToken"}),", which you can include in your next query to get the 50 next results \u2013 a process we can iterate as long as we want to. Let us generalize our previous code to collect the N first pages of results for our query:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'## > Loop to retrieve videos related to search query from multiple pages < \r\n \r\nN = 2 # We set N to 2 to define that we want the top 2 pages of results. \r\n\r\n# The \u201cnextPageToken\u201d variable will be used in the for loop to store the ID of the next page.\r\nnext_page_token = None     \r\nsearch_results = list()  # An empty list to store the query results\r\n \r\nfor i in tqdm(range(N)): # The "tqdm" wrapper around the "ids_list" variable allows us to see a progress bar\r\n \r\n    # Retrieve a page of results \r\n    if next_page_token is None:\r\n# i.e. if this is the request for the first page, we do not use it as a parameter\r\n        request = youtube.search().list(\r\n            part="snippet",\r\n            maxResults=50,\r\n            publishedAfter="2024-10-01T00:00:00Z",\r\n            publishedBefore="2024-11-06T00:00:00Z",\r\n            order="viewCount",\r\n            q="election fraud | stolen election | election lie",\r\n            relevanceLanguage="en",\r\n            type="video"\r\n        )\r\n        page_response = request.execute()\r\n        search_results.append(page_response)   \r\n    else:\r\n # If it not None however, we use "nextPageToken" to specify the "pageToken" as a query parameter\r\n        request = youtube.search().list(\r\n            part="snippet",\r\n            maxResults=50,\r\n            publishedAfter="2024-10-01T00:00:00Z",\r\n            publishedBefore="2024-11-06T00:00:00Z",\r\n            order="viewCount",\r\n            q="election fraud | stolen election | election lie",\r\n            relevanceLanguage="en",\r\n            type="video",\r\n\t  pageToken=next_page_token # here goes our token\r\n        )\r\n        page_response = request.execute()\r\n        search_results.append(page_response)\r\n \r\n    # Try to retrieve the "nextPageToken" if there is one.\r\n    try:\r\n        next_page_token = page_response["nextPageToken"]\r\n        \r\n    # If the response does not have a "nextPageToken" field, we simply break out of the loop\r\n    except KeyError:\r\n        break  \r\n\n'})}),"\n",(0,i.jsx)(t.admonition,{title:"Note",type:"hub-note",children:(0,i.jsxs)(t.p,{children:["If you are only interested in the video results, you can also extract the respective data inside this loop by extending the ",(0,i.jsx)(t.code,{children:"search_results"})," list with ",(0,i.jsx)(t.code,{children:'page_response["items"]'}),"."]})}),"\n",(0,i.jsx)(t.h2,{id:"data-collection-methods-video-information",children:"Data collection methods: Video information"}),"\n",(0,i.jsxs)(t.p,{children:["As seen above, the information for each video we can collect directly from the search query is limited. To obtain more detailed data like the views or comment count, we turn to the ",(0,i.jsx)(t.code,{children:"videos()"})," resource and again use the ",(0,i.jsx)(t.code,{children:"list()"})," method.  For instance, the same video shown above offers the following statistics:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"{'viewCount': '5325494', 'likeCount': '143592', 'favoriteCount': '0', 'commentCount': '8695'}\n"})}),"\n",(0,i.jsxs)(t.p,{children:["Let\u2019s write a function that takes a video_id as input und calls the API to retrieve more detailed information. Crucially, the ",(0,i.jsx)(t.code,{children:"youtube.videos().list()"})," request can take multiple id\u2019s as input, so we can speed up our data collection with batches."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'# Our function to get video details\r\ndef get_video_details(video_ids):\r\n    if not video_ids:\r\n        return []\r\n \r\n    # define batch size (limit is 50 again)\r\n    batch_size = 50 \r\n    videos = [] \r\n \r\n    # process video id\'s in batches\r\n    for i in range(0, len(video_ids), batch_size):\r\n        batch = video_ids[i:i + batch_size]\r\n \r\n        details_request = youtube.videos().list(\r\n            part="snippet,statistics",\r\n            id=",".join(batch) \r\n        )\r\n        details_response = details_request.execute()\r\n \r\n        videos.extend([\r\n            {\r\n                "title": video["snippet"]["title"],\r\n                "published_at": video["snippet"]["publishedAt"],\r\n                "channel_title": video["snippet"]["channelTitle"],\r\n                "view_count": video["statistics"].get("viewCount", 0),\r\n                "like_count": video["statistics"].get("likeCount", 0),\r\n                "dislike_count": video["statistics"].get("dislikeCount", 0),\r\n                "comment_count": video["statistics"].get("commentCount", 0)\r\n            }\r\n            for video in details_response.get("items", [])\r\n        ])\r\n \r\n    return videos\n'})}),"\n",(0,i.jsx)(t.p,{children:"Now we extract the ID\u2019s of our 100 most viewed videos related to election integrity and use the function above to retrieve more interesting information about the first 5 of them:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"# Extract unique video ID\u2019s from search results\r\nvideo_ids = list(set(video[\"id\"][\"videoId\"] for page in search_results for video in page.get(\"items\", [])))\r\n \r\n# limit to first 5 videos\r\nN = 5\r\nvideo_ids = video_ids[:N]\r\n \r\n# use the function \r\nlatest_videos = get_video_details(video_ids)\r\n \r\n# print (some) info\r\nfor video in latest_videos:\r\n    print(f\"Title: {video['title']}, Published: {video['published_at']}, \"\r\n          f\"Channel: {video['channel_title']}, Views: {video['view_count']}, \"\r\n          f\"Likes: {video['like_count']}, Dislikes: {video['dislike_count']}, \"\r\n          f\"Comments: {video['comment_count']}\")\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:'Title: DEBUNKING The Latest Election Lies From MAGA Senator | Bulwark Takes, Published: 2024-10-07T02:19:12Z, Channel: The Bulwark, Views: 332857, Likes: 20952, Dislikes: 0, Comments: 2460\r\n\r\nTitle: Voter Registration Fraud Discovered in Pennsylvania, Published: 2024-10-25T18:55:56Z, Channel: The Michael Lofton Show, Views: 567625, Likes: 9243, Dislikes: 0, Comments: 3285\r\n\r\nTitle: Will Trump\u2019s baseless stolen election claims spark another Capitol attack? | ABC News, Published: 2024-11-03T22:56:07Z, Channel: ABC News (Australia), Views: 3994, Likes: 47, Dislikes: 0, Comments: 0\r\n\r\nTitle: Can Kamala Harris defeat Trump\u2019s election lies in battleground Georgia? | Anywhere but Washington, Published: 2024-10-03T11:54:15Z, Channel: The Guardian, Views: 99329, Likes: 1718, Dislikes: 0, Comments: 510\r\n\r\nTitle: "Trump\'s 2024 Election Strategy: Lies and Controversy!", Published: 2024-11-02T11:09:09Z, Channel: MJ News, Views: 6, Likes: 0, Dislikes: 0, Comments: 1\r\n \n'})}),"\n",(0,i.jsxs)(t.p,{children:["As of now, this data is stored in ",(0,i.jsx)(t.code,{children:"latest_videos"})," as a list of dictionaries. To make it more manageable, we simply convert it to a pandas ",(0,i.jsx)(t.code,{children:"DataFrame"})," object (a table, basically). This way, we can also easily export it to a CSV or Excel file."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"data = pd.DataFrame(latest_videos)\r\nprint(data)\n"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.em,{children:"Table 1: Results for video detail collection of the first five videos"})}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{style:{textAlign:"center"},children:"index"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"title"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"published_at"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"channel_title"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"view_count"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"like_count"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"dislike_count"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"comment_count"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"0"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"DEBUNKING The Latest Election Lies From MAGA S..."}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"2024-10-07T02:19:12Z"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"The Bulwark"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"332857"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"20952"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"0"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"2460"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"Voter Registration Fraud Discovered in Pennsyl..."}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"2024-10-25T18:55:56Z"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"The Michael Lofton Show"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"567625"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"9243"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"0"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"3285"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"2"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"Will Trump\u2019s baseless stolen election claims s..."}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"2024-11-03T22:56:07Z"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"ABC News (Australia)"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"3994"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"47"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"0"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"0"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"3"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"Can Kamala Harris defeat Trump\u2019s election lies..."}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"2024-10-03T11:54:15Z"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"The Guardian"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"99329"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"1718"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"0"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"510"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"4"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"\"Trump's 2024 Election Strategy: Lies and Cont..."}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"2024-11-02T11:09:09Z"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"MJ News"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"6"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"0"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"0"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"1"})]})]})]}),"\n",(0,i.jsx)(t.h2,{id:"data-collection-methods-comments",children:"Data collection methods: Comments"}),"\n",(0,i.jsxs)(t.p,{children:["Comment sections can be collected via the ",(0,i.jsx)(t.code,{children:"comments()"})," resource and ",(0,i.jsx)(t.code,{children:"list()"})," method. A single query for the example video looks like this:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'request = youtube.commentThreads().list(\r\n    part="snippet,id,replies",\r\n    maxResults=100, #For this resource, the max amount of results is 100 \r\n    order="time",\r\n    videoId="IPUhRjAMCTo"\r\n)\r\ncomment_response = request.execute()\n'})}),"\n",(0,i.jsx)(t.p,{children:"With the output data for a single comment in the thread:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"{'kind': 'youtube#commentThread',\r\n 'etag': 'FjHUXM2rssJNyLjk0GUPrIP1AeY',\r\n 'id': 'Ugy8fFs_mIdgiaBW7wF4AaABAg',\r\n 'snippet': {'channelId': 'UCwWhs_6x42TyRM4Wstoq8HA',\r\n  'videoId': 'IPUhRjAMCTo',\r\n  'topLevelComment': {'kind': 'youtube#comment',\r\n   'etag': 'Kp3rpMeuZ1_egtsYT6K_GX9-rrU',\r\n   'id': 'Ugy8fFs_mIdgiaBW7wF4AaABAg',\r\n   'snippet': {'channelId': 'UCwWhs_6x42TyRM4Wstoq8HA',\r\n    'videoId': 'IPUhRjAMCTo',\r\n    'textDisplay': 'No do the same for Kamala and Biden. Much more material.',\r\n    'textOriginal': 'No do the same for Kamala and Biden. Much more material.',\r\n    'authorDisplayName': '@stevenberry3294',\r\n    'authorProfileImageUrl': 'https://yt3.ggpht.com/ytc/AIdro_mljzddy7jo9d1eT87Vxkf-wgEsl_KEIealLasN5hw=s48-c-k-c0x00ffffff-no-rj',\r\n    'authorChannelUrl': 'http://www.youtube.com/@stevenberry3294',\r\n    'authorChannelId': {'value': 'UCiJyUwZOM8CL07N7RjjmWdA'},\r\n    'canRate': True,\r\n    'viewerRating': 'none',\r\n    'likeCount': 0,\r\n    'publishedAt': '2025-03-04T02:12:13Z',\r\n    'updatedAt': '2025-03-04T02:12:13Z'}},\r\n  'canReply': True,\r\n  'totalReplyCount': 0,\r\n  'isPublic': True}}\n"})}),"\n",(0,i.jsx)(t.p,{children:"Having constructed the comment collection query for a single video, we can write a loop to retrieve all comments for the same 100 most viewed videos related to election integrity."}),"\n",(0,i.jsx)(t.p,{children:"This loop does two things:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"It iterates over each video ID"}),"\n",(0,i.jsx)(t.li,{children:"It iterates through all comment results for each video id with pagination"}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'comment_results = dict() # This time, we create an empty dictionary to store the comment query results\r\n \r\n# iterate over the video IDs\r\nfor id in tqdm(video_ids): \r\n \r\n    # this initialises the comment results for this particular video ID to be an empty list\r\n    comment_results[id] = list()\r\n    \r\n    # Try to retrieve the first page of comments for the video\r\n    try:\r\n        request = youtube.commentThreads().list(\r\n            part="snippet,id,replies",\r\n            maxResults=100,\r\n            order="time",\r\n            videoId=id\r\n        )\r\n        comment_response = request.execute()\r\n        comment_results[id].append(comment_response)\r\n \r\n# Some videos might have disable comments. \r\n# If so, these lines of code will catch the error and simply move on to the next video.\r\n    except Exception as e:  \r\n        print(id, e)\r\n        continue  \r\n \r\n    # Try to retrieve the "nextPageToken" if there is one.\r\n    try:\r\n        nextPageToken = comment_response["nextPageToken"]\r\n        \r\n # If the response does not have a "nextPageToken" field, the loop moves on to the next video\r\n    except KeyError:\r\n        continue \r\n \r\n # Given a value was found, this retrieves the comments until a "nextPageToken" can\u2019t be found\r\n    while True:\r\n        request = youtube.commentThreads().list(\r\n            part="snippet,id,replies",\r\n            maxResults=100,\r\n            order="time",\r\n            videoId=id,\r\n            pageToken=nextPageToken\r\n        )\r\n        comment_response = request.execute()\r\n        comment_results[id].append(comment_response)\r\n        try:\r\n            nextPageToken = comment_response["nextPageToken"]\r\n        except KeyError:\r\n            break\r\n \n'})}),"\n",(0,i.jsx)(t.p,{children:"Now we retrieve the number of comment threads for each of the first three videos and the respective total number of comments we were able to collect."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'stats_list = list()\r\n \r\nfor i, id in enumerate(comment_results):\r\n    nb_threads = 0\r\n    nb_comments = 0\r\n \r\n    for result in comment_results[id]:\r\n        nb_threads += len(result["items"])\r\n        for item in result["items"]:\r\n            nb_comments += 1\r\n            if "replies" in item:\r\n                nb_comments += len(item["replies"]["comments"])\r\n\r\n \r\n    stats_list.append({"video_id": id, "nb_threads": nb_threads, "nb_comments": nb_comments})\r\n \r\nstats_df = pd.DataFrame(stats_list)\n'})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.em,{children:"Table 2: Results for comment collection of the first three videos"})}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"video_id"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"nb_threads"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"nb_comments"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"IPUhRjAMCTo"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"5317"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"6337"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"chIsUyT5mVg"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"4676"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"5566"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"yiowo1L58rg"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"3874"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"4379"})]})]})]}),"\n",(0,i.jsx)(t.admonition,{title:"Note",type:"hub-note",children:(0,i.jsxs)(t.p,{children:["We can use the comment data collected to analyze the networks that develop in these comment sections. This can be found in the chapter ",(0,i.jsx)(t.a,{href:"/docs/docs/04_data-analysis/04_03_social-network-analysis",children:'"Social Network Analysis"'}),". For this, use the unique ID\u2019s we gathered from the comment authors and their replies and convert them to a simple edge list."]})}),"\n",(0,i.jsx)(t.h2,{id:"data-collection-methods-channels",children:"Data collection methods: Channels"}),"\n",(0,i.jsxs)(t.p,{children:["Lastly, if we have a set of channels we want to monitor in terms of their impact and the contents they disseminate, we can retrieve this data with ",(0,i.jsx)(t.code,{children:"channels()"})," and ",(0,i.jsx)(t.code,{children:"list()"})," method and subsequently utilize the methods we already learned to collect all the information we need."]}),"\n",(0,i.jsx)(t.p,{children:"We first write a function to retrieve some channel\u2019s general information and statistics. Then, we write a function that displays the unique ID of that channel. Lastly, we write a function to get the latest videos this channel has published. In this example, we retrieve information about the channel \u201c@AntiSpiegel\u201d that is associated with the media outlet \u201cAnti-Spiegel\u201d run by the prominent Russian propagandist Thomas R\xf6per."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"Channel",src:n(690).A+"",width:"454",height:"146"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.em,{children:"Screenshot of the AntiSpiegel YouTube channel"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'# define function to get a channel\'s information\r\ndef get_channel_info(user_handle:str):\r\n    \r\n    request = youtube.channels().list(\r\n        part="snippet,statistics",\r\n        forHandle= user_handle\r\n    )\r\n    \r\n    response = request.execute()\r\n    \r\n    info = response[\'items\'][0][\'snippet\']\r\n    statistics = response[\'items\'][0][\'statistics\']\r\n \r\n    return info,statistics\r\n \r\n# define function to get channel id\r\ndef get_channel_id(user_handle):\r\n    request = youtube.search().list(\r\n        part="snippet",\r\n        q=user_handle,\r\n        type="channel",\r\n        maxResults=1\r\n    )\r\n    response = request.execute()\r\n    \r\n    if response["items"]:\r\n        print(f"Channels found: {len(response["items"])}")\r\n        return response["items"][0]["id"]["channelId"]\r\n    else:\r\n        print("No channel found with that username")\r\n        return None\r\n \r\n \r\n# define function to get latest video id\'s\r\ndef get_latest_videos(channel_id, max_results:int=5,after:str= \'2025-01-01\',before:str=\'2025-02-23\'):\r\n    request = youtube.search().list(\r\n        part="id",\r\n        channelId=channel_id,\r\n        order="date",\r\n        publishedAfter=f"{after}T00:00:00Z",\r\n        publishedBefore=f"{before}T00:00:00Z",\r\n        maxResults=max_results,\r\n        type="video"\r\n    )\r\n    response = request.execute()\r\n    \r\n    video_ids = [video["id"]["videoId"] for video in response.get("items", [])]\r\n    video_ids = video_ids[:max_results]\r\n \r\n    return video_ids\r\n\n'})}),"\n",(0,i.jsx)(t.p,{children:'Applying these functions to the "@AntiSpiegel" YouTube channel looks like this:'}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'channel_info,statistics = get_channel_info("@AntiSpiegel")\r\nprint("Channel info:",channel_info[\'title\'],"\\n\\n","Channel statistics:",statistics)\r\n \r\n# retrieve channel id for any account\r\nchannel_id = get_channel_id("@AntiSpiegel")\r\nprint(f"\\n Channel ID: {channel_id}")\r\n \r\n# retrieve id\'s of latest videos on XXXX account\r\nvideo_ids = get_latest_videos(channel_id)\r\nprint(video_ids)\r\n\n'})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"Channel info: Anti Spiegel \r\n \r\nChannel statistics: {'viewCount': '14460636', 'subscriberCount': '144000', 'hiddenSubscriberCount': False, 'videoCount': '113'}\r\n \r\nChannel ID: UC93mqUPbNmHZhl4fAVvZWpQ\r\n['IJyCAsBJJEo', 'm1jAhFRq3YI', 'T37-ST2kkiI', 'RyxFcVMDJts', 'O9P1eAZ9Sc0']\n"})}),"\n",(0,i.jsx)(t.p,{children:"To sum up, the combination of functions and methods provided in this tutorial equip you to closely monitor and retrieve a comprehensive set of datapoints from YouTube. You can now construct, edit and execute queries for any resource the API provides. Wrapping these queries with some Python code allows you to store and analyse data on channels, videos about topics of interest as well as discourses in the comment sections. Crucially, the steps in this tutorial prepare you to explore the vast landscape of content on YouTube and gain insights into the production and dissemination of disinformation across different geographical or societal contexts."}),"\n",(0,i.jsx)(t.h2,{id:"references",children:"References"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"Allgaier, J. (2019). Science and environmental communication on YouTube: Strategically distorted communications in online videos on climate change and climate engineering. Frontiers in communication, 4, 36."}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["Kn\xfcpfer, C., Schwemmer, C., & Heft, A. (2023). Politicization and Right-Wing Normalization on YouTube: A Topic-Based Analysis of the \u201cAlternative Influence Network\u201d. International Journal Of Communication, 17, 23. Retrieved from ",(0,i.jsx)(t.a,{href:"https://ijoc.org/index.php/ijoc/article/view/20369",children:"https://ijoc.org/index.php/ijoc/article/view/20369"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["Maldida.es. (2025). \u201eEuropean politician crushes Spanish politician in the European Parliament\u201c: A network of disinformation channels on YouTube. Maldita.es. Retrieved April 09, 2025, from ",(0,i.jsx)(t.a,{href:"https://maldita.es/malditobulo/20250313/network-channels-youtube-disinformation-spanish-politics-eu/",children:"https://maldita.es/malditobulo/20250313/network-channels-youtube-disinformation-spanish-politics-eu/"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["Richardson, L., & Flannery O\u2019Connor, J. (2023, August 24). Complying with the Digital Services Act. The Keyword. Retrieved April 09, 2025, from ",(0,i.jsx)(t.a,{href:"https://blog.google/around-the-globe/google-europe/complying-with-the-digital-services-act/",children:"https://blog.google/around-the-globe/google-europe/complying-with-the-digital-services-act/"})]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}function u(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},2057:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/schwenn-c983e8579f9e1ca4b709e7349d84dc3b.jpg"},690:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/roeper_page_example-d370e541a7aec0bb4ba0040b448d45d5.png"}}]);
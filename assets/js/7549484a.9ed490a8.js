"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7327],{850:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>a,metadata:()=>o,toc:()=>c});var r=n(4848),s=n(8453);const a={title:"Webscraping",sidebar_position:4},i="Webscraping techniques with R",o={id:"data-collection/03_03_web-scraping-intro",title:"Webscraping",description:"<AuthorCard",source:"@site/docs/03_data-collection/03_03_web-scraping-intro.mdx",sourceDirName:"03_data-collection",slug:"/data-collection/03_03_web-scraping-intro",permalink:"/docs/data-collection/03_03_web-scraping-intro",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"Webscraping",sidebar_position:4},sidebar:"docs",previous:{title:"Data Collection of Facebook and Instagram Ads",permalink:"/docs/data-collection/03_00_platform-specific guidelines/03_04_data-collection_meta_ads"},next:{title:"index",permalink:"/docs/data-analysis/"}},l={},c=[{value:"Current challenges of webscraping",id:"current-challenges-of-webscraping",level:2},{value:"What you will learn in this chapter",id:"what-you-will-learn-in-this-chapter",level:3},{value:"Webscraping: The current state",id:"webscraping-the-current-state",level:3},{value:"Diving into a pro-Russian disinformation world",id:"diving-into-a-pro-russian-disinformation-world",level:2},{value:"Analyzing scraped data and next steps",id:"analyzing-scraped-data-and-next-steps",level:3},{value:"Scraping huge datasets via parallelization",id:"scraping-huge-datasets-via-parallelization",level:3},{value:"Second example: AUF1 as a dynamic website",id:"second-example-auf1-as-a-dynamic-website",level:3},{value:"Literature",id:"literature",level:2}];function d(e){const t={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components},{AuthorCard:a,LanguageChip:i,LastUpdatedByChip:o,PlatformChip:l,VideoCard:c}=t;return a||p("AuthorCard",!0),i||p("LanguageChip",!0),o||p("LastUpdatedByChip",!0),l||p("PlatformChip",!0),c||p("VideoCard",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"webscraping-techniques-with-r",children:"Webscraping techniques with R"})}),"\n",(0,r.jsx)(l,{platform:"Websites"}),"\n",(0,r.jsx)(i,{lang:"R"}),"\n",(0,r.jsx)(a,{name:"Josef Holnburger",avatar:"JH",avatarSrc:n(465).A,position:"Center for Monitoring, Analysis and Strategy (CeMAS)",website:"https://cemas.io/team/josef-holnburger/",twitter:"https://twitter.com/holnburger"}),"\n",(0,r.jsx)(o,{authorOriginal:"Josef Holnburger",createdOn:"13.09.2024"}),"\n",(0,r.jsx)(c,{videoSrc:"https://github.com/bertelsmannstift/data-knowledge-hub_videos/raw/main/videos/UPDEM_Holnburger_540.mp4",thumbnailSrc:"https://github.com/bertelsmannstift/data-knowledge-hub_videos/raw/main/thumbnails/UPDEM_Holnburger_540.png"}),"\n",(0,r.jsx)(t.h2,{id:"current-challenges-of-webscraping",children:"Current challenges of webscraping"}),"\n",(0,r.jsxs)(t.p,{children:["Numerous social networks recently decided to seal off their APIs more strongly and, for example, to offer them only in exchange for payment (or not at all). This increasingly limits the possibility for scientists to systematically capture important parts of digital discourse and to examine its influence on society. The lasting consequences of such decisions are expected to become more evident in the upcoming months and years, yet an immediate effect is already observable: The relevance of webscraping is on the rise again. As a means to replace the sealed-off APIs, many programmers, especially with regard to X (Twitter), resorted to systematically retrieving data via the X website \u2013 apparently at such a high frequency that Elon Musk\u2019s X (Twitter) decided to put all of the website\u2019s posts behind a login wall, making it more difficult to capture X\u2019s (Twitter) data via scraping (",(0,r.jsx)(t.a,{href:"https://mashable.com/article/elon-musk-twitter-login-requirement-temporary",children:"Binder 2023"}),")."]}),"\n",(0,r.jsx)(t.p,{children:"This is a step back: In the past, many social platforms offered an API with (often) free quotas precisely to avoid the burden of webscraping on servers (Khder 2021, p.147). Moreover, webscraping comes with a variety of ethical, technical and legal concerns and questions (see Khder 2021). Even if one is only interested in a fraction of the publicly accessible data, webscraping requires capturing the data of the entire website instead of merely extracting the relevant information: Thus, significantly more data is collected than is necessary, for example, to provide a scientific answer to a hypothesis. Images are loaded, clicks are simulated \u2013 allowing the reconstruction of individual user behavior."}),"\n",(0,r.jsxs)(t.p,{children:["While this chapter shows you the ropes of responsible webscraping, it is critical to emphasize that is primarily the providers of social networks and websites who are called upon to offer the interfaces to their data for civil society and science in a suitable manner \u2013 after all, their online presence significantly shapes public discourse. This influence must be critically monitored and analyzed, which is why monitoring for research purposes must be supported. Currently many platform operators are resisting this responsibility and the need for transparency \u2013 let\u2019s hope the Digital Services Act will improve that situation by forcing platform operators to enable data access (see ",(0,r.jsx)(t.a,{href:"https://edmo.eu/2023/05/30/members-of-the-edmo-task-force-on-disinformation-on-the-war-in-ukraine-submit-feedback-to-the-ec-call-for-evidence-on-the-provisions-in-the-dsa-related-to-data-access/",children:"EDMO 2023"}),"; ",(0,r.jsx)(t.a,{href:"https://algorithmwatch.org/en/dsa-empower-public-interest-research-data-access/",children:"AlgorithmWatch 2023"}),")."]}),"\n",(0,r.jsx)(t.h3,{id:"what-you-will-learn-in-this-chapter",children:"What you will learn in this chapter"}),"\n",(0,r.jsx)(t.p,{children:"This chapter therefore aims to highlight three things:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"how to access such content, using concrete examples;"}),"\n",(0,r.jsx)(t.li,{children:"how to deal with scraped data within the scope of one\u2019s own responsibility to prevent overloading web servers and"}),"\n",(0,r.jsx)(t.li,{children:"to access data responsibly and according to modern standards."}),"\n"]}),"\n",(0,r.jsxs)(t.p,{children:["To collect data via webscraping (1), you will learn how to use the programming language R and the library rvest, using the tidy principles ",(0,r.jsx)(t.a,{href:"http://www.jstatsoft.org/v59/i10/",children:"Wickham 2014"}),". Intended for beginners as well as advanced programmers, this is meant to make the code presented here easy to access and analyze. Additional references, links and tutorials are included throughout."]}),"\n",(0,r.jsx)(t.h3,{id:"webscraping-the-current-state",children:"Webscraping: The current state"}),"\n",(0,r.jsxs)(t.p,{children:["Meanwhile numerous packages for programming languages are available, which simplify the collection of data significantly. In the ",(0,r.jsx)(t.strong,{children:"Python"})," world ",(0,r.jsx)(t.a,{href:"https://www.crummy.com/software/BeautifulSoup/bs4/doc/",children:(0,r.jsx)(t.code,{children:"Beautiful Soup"})})," is one of the most important program libraries, in the ",(0,r.jsx)(t.strong,{children:"R"})," universe ",(0,r.jsx)(t.a,{href:"https://rvest.tidyverse.org/",children:(0,r.jsx)(t.code,{children:"rvest"})})," takes a key role: Both libraries allow you to capture data from static web pages and extract elements from it."]}),"\n",(0,r.jsx)(t.admonition,{type:"note",children:(0,r.jsxs)(t.p,{children:["Other programming languages and associated libraries also enable comprehensive web scraping -- for example, ",(0,r.jsx)(t.a,{href:"https://pptr.dev/",children:"Puppeteer"})," is a good way to capture both static and dynamic web pages via Node.js. For the purposes of this article, we will take a comprehensive look at the ",(0,r.jsx)(t.code,{children:"rvest"})," package and its capabilities -- and also point out options when, for example, pages do not have static elements but should still be captured. For an example of how to use puppeteer see ",(0,r.jsx)(t.a,{href:"/docs/data-analysis/04_00_code-samples/hashtag-analysis",children:"this chapter in the knowledge hub"}),"."]})}),"\n",(0,r.jsxs)(t.p,{children:["In this chapter, you will ",(0,r.jsxs)(t.strong,{children:["be introduced to the ",(0,r.jsx)(t.code,{children:"rvest"})," package and its capabilities"]})," \u2013 and learn about options on how to scrape dynamic pages."]}),"\n",(0,r.jsxs)(t.p,{children:["To do so, we will use two sites as examples: the pro-Russian disinformation website Anti-Spiegel.ru of conspiracy ideologist Thomas R\xf6per (see ",(0,r.jsx)(t.a,{href:"https://www.belltower.news/desinformations-medien-der-anti-spiegel-russische-propaganda-und-verschwoerungsmythen-132357/",children:"Balzer 2022"}),") and the conspiracy ideology media portal AUF1 (see ",(0,r.jsx)(t.a,{href:"https://correctiv.org/faktencheck/hintergrund/2023/04/27/was-hinter-auf1-stefan-magnet-und-der-ausbreitung-des-oesterreichischen-verschwoerungssenders-steckt-desinformation-und-rechte-hetze/",children:"Scherndl and Thom 2023"}),") run by right-wing extremist Stefan Magnet. While R\xf6per\u2019s Anti-Spiegel is a static website (operated with Wordpress) \u2013 i.e. a website which is rendered by the server \u2013 AUF1 is a website which, like many other modern websites, is only partially rendered and only fully loaded in the browser."]}),"\n",(0,r.jsx)(t.admonition,{title:"Note",type:"hub-note",children:(0,r.jsxs)(t.p,{children:["An overview of the different principles of web content delivery can be found in this ",(0,r.jsx)(t.a,{href:"https://www.freecodecamp.org/news/rendering-patterns/",children:"article"}),"."]})}),"\n",(0,r.jsxs)(t.p,{children:["Both examples are well suited to demonstrate different ways of scraping with ",(0,r.jsx)(t.code,{children:"rvest"}),". Content-wise, they influence online discourse with anti-democratic worldviews and disinformation regarding, for example, the Russian war on Ukraine or the topic of vaccinations and pandemics. Their content continues to influence (at least parts of) society in the German-speaking world. Therefore, they not only serve as an example for data collection, but also show that it is important to deeply investigate such platforms from a societal cohesion perspective."]}),"\n",(0,r.jsx)(t.h2,{id:"diving-into-a-pro-russian-disinformation-world",children:"Diving into a pro-Russian disinformation world"}),"\n",(0,r.jsxs)(t.p,{children:["The Russian propagandist Thomas R\xf6per published numerous articles on his website in which he belittles the consequences of, for example, the Russian war of aggression against the Ukraine and denies war crimes (see ",(0,r.jsx)(t.a,{href:"https://www.journalist.de/startseite/detail/article/im-desinformationskrieg",children:"Journalist 2022"}),"). He not only writes his own articles, but also publishes news reports from the Russian news agency TASS and the Kremlin\u2019s media outlet Russia Today. To determine which domains are cited particularly frequently, these sections will provide guidance on the necessary steps. Additionally, potential challenges during the scraping process will be addressed."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'library(rvest)\r\n# Several packages of the **tidyverse** will be used\r\n# for example `dplyr` for data manipulation or `ggplot` to visualize the data we accessed.\r\n# Therefore, the whole tidyverse is being loaded.\r\nlibrary(tidyverse)\r\n# Glue is used for better data annotations in the graphs. This is optional.\r\nlibrary(glue)\r\n\r\npage <- read_html("https://www.anti-spiegel.ru/category/aktuelles/")\r\n\n'})}),"\n",(0,r.jsxs)(t.p,{children:["On his website we can find a link with which we can access all his articles. ",(0,r.jsx)(t.code,{children:"rvest"})," can make the data usable for our further analysis. Via ",(0,r.jsx)(t.code,{children:"read_html"})," we can read a page, then we can access different elements of the web page via the function ",(0,r.jsx)(t.code,{children:"html_elements()"}),". The easiest way is to use so called CSS selectors to choose the section which should be extracted: CSS selectors are different patterns which can be used to access different elements of an HTML page."]}),"\n",(0,r.jsx)(t.admonition,{title:"Note",type:"hub-note",children:(0,r.jsxs)(t.p,{children:["An overview of different CSS selector patterns can be found at ",(0,r.jsx)(t.a,{href:"https://www.w3schools.com/cssref/css_selectors.php",children:"W3Schools"}),".\r\nTo make it easier to choose the right selectors, you can use the Google Chrome extension ",(0,r.jsx)(t.a,{href:"https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb",children:"SelectorGadget"}),": By simply selecting and deselecting on a web page, the right CSS selector for the right segment can often be found quickly, as in the example of the title of each article here. Selecting the title and deselecting the ticker shows, that currently 20 titles are being highlighted using the selector ",(0,r.jsx)(t.code,{children:"image-left .title"})]})}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.img,{alt:"Selectorgadget example on R\xf6pers page",src:n(8962).A+"",width:"1159",height:"1031"}),"\r\n",(0,r.jsx)(t.em,{children:"Selectorgadget example on R\xf6pers page"})]}),"\n",(0,r.jsxs)(t.p,{children:["Using the CSS selectors, you can now determine the segments that are relevant to you \u2013 afterwards, you will write a function that will store all the relevant information in one record. ",(0,r.jsx)(t.code,{children:"rvest"})," also has useful support functions here, such as ",(0,r.jsx)(t.code,{children:"html_text()"}),". This function allows you to convert html types into simple text vectors; ",(0,r.jsx)(t.code,{children:"html_text2()"})," extends this function and additionally removes unnecessary white spaces."]}),"\n",(0,r.jsx)(t.admonition,{title:"Hint",type:"community",children:(0,r.jsxs)(t.p,{children:["You can find a good introduction to rvest and documentation on its ",(0,r.jsx)(t.a,{href:"https://rvest.tidyverse.org/",children:"main page"}),"."]})}),"\n",(0,r.jsxs)(t.p,{children:["The most important functions for this examples case are ",(0,r.jsx)(t.code,{children:"html_elements()"})," and ",(0,r.jsx)(t.code,{children:"html_attr()"})," \u2013 they allow you to extract elements and attributes (for example, the link from the href attribute of a ",(0,r.jsx)(t.code,{children:"<a>"})," node). rvest makes use of many functions of the xml2 package, so it\u2019s worth having a look at its documentation."]}),"\n",(0,r.jsx)(t.admonition,{title:"Note",type:"hub-note",children:(0,r.jsxs)(t.p,{children:["For example, ",(0,r.jsx)(t.code,{children:"html_structure()"})," from xml2 is useful to get an overview of the structure of a web page."]})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'page %>%\r\n  html_elements(".image-left .title") %>%\r\n  html_text()\n'})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:' [1] "Der manipulierte Whistleblower-Bericht"\r\n [2] "Die UNO als Instrument des Westens"\r\n [3] "Der Bev\xf6lkerungsr\xfcckgang macht die Ukraine wirklich zum \u201eLand 404\u201c"\r\n [4] "Wem ist nichts mehr heilig?"\r\n [5] "Was Spiegel-Leser \xfcber das Treffen von Lukaschenko und Putin (nicht) erfahren"\r\n [6] "Droht eine Eskalation zwischen den USA und Russland?"\r\n [7] "Die Gesch\xe4fte der Bidens in der Ukraine"\r\n [8] "Der Schwarze Peter geht an Kiew"\r\n [9] "K\xe4uferin von Hunter Bidens Bildern bekommt einen Posten in der US-Regierung"\r\n[10] "Internetkonzerne, KI und totale Zensur und Kontrolle"\r\n[11] "Estland verbietet Feiern zum Jahrestag der Befreiung von Nazi-Deutschland"\r\n[12] "Die Bidens: Eine schrecklich nette Familie"\r\n[13] "Die Versuche der USA, die NATO auf den Pazifik auszudehnen"\r\n[14] "Die BRICS laden 70 Staatschefs ein, aber niemanden aus dem Westen"\r\n[15] "Mein neues Buch ist jetzt im Handel"\r\n[16] "Putin schreibt einen Artikel \xfcber die Beziehungen zu Afrika"\r\n[17] "Wie die US-Demokraten die Korruptionsskandale des Biden-Clans zu verschleiern versuchen"\r\n[18] "Was wird aus dem Getreideabkommen?"\r\n[19] "Ukrainische Gegenoffensive laut Putin gescheitert: Die Ereignisse des Wochenendes"\r\n[20] "Unsere Fahrt an die Front in Saporoschschje"\n'})}),"\n",(0,r.jsx)(t.p,{children:"In most cases, not all content relevant to the investigation can be found on one page but will be distributed over several pages. In this example, you can find over 200 pages that can be extracted. Either way, you can either manually compile the pages you want to scrape or extract them automatically and reproducibly from the overview page."}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.img,{src:n(6017).A+"",width:"1164",height:"820"}),"\r\n",(0,r.jsx)(t.em,{children:"Next page example on R\xf6pers page"})]}),"\n",(0,r.jsxs)(t.p,{children:["Using the CSS selector ",(0,r.jsx)(t.code,{children:".page-numbers"})," we can extract all page numbers - however, here we also extract the ",(0,r.jsx)(t.code,{children:"Next"})," navigation object. To extract the relevant information from these objects (here for example the last number) you must use regular expressions. ",(0,r.jsx)(t.strong,{children:"Regular expressions"})," are certain terms and symbols that search for patterns in a text, in the following example a number that is not followed by another number."]}),"\n",(0,r.jsx)(t.admonition,{type:"hub-note",children:(0,r.jsxs)(t.p,{children:["A useful extension for R is ",(0,r.jsx)(t.a,{href:"https://github.com/gadenbuie/regexplain",children:"Regexplain"}),". This add-on for RStudio allows to test various regular expressions directly in the interface. Many tips and tools can also be found online, for example ",(0,r.jsx)(t.a,{href:"https://regex101.com/",children:"regex101"}),"."]})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'last_page_nmbr <- page %>%\r\n  html_elements(".page-numbers") %>%\r\n  html_text() %>%\r\n  # Collapse the vector to one string separated by a space.\r\n  paste(collapse = " ") %>%\r\n  # Regular expression for selecting the last digit in a string.\r\n  str_extract("(\\\\d+)(?!.*\\\\d)")\n'})}),"\n",(0,r.jsxs)(t.p,{children:["In the next step you can now write your own function that extracts the relevant sections from each overview page. The result is output as a ",(0,r.jsx)(t.code,{children:"tibble"})," \u2013 a ",(0,r.jsx)(t.code,{children:"data.frame"})," object that also provides a quick overview of the data in the console and can be used for. To avoid scraping later, you should store the raw HTML in a column of the ",(0,r.jsx)(t.code,{children:"tibble"}),". This also allows you to extract additional data, such as the number of comments, later. Such a procedure is also a best practice, as it allows you to avoid a larger server load for the site operator due to multiple scraping."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'get_article_overview <- function(url) {\r\n  page <- read_html(url)\r\n\r\n  tibble(\r\n    title = page %>%\r\n      html_elements(".image-left .title") %>%\r\n      html_text(),\r\n    subtitle = page %>%\r\n      html_elements(".image-left .dachzeile") %>%\r\n      html_text(),\r\n    url = page %>%\r\n      html_elements(".image-left .title") %>%\r\n      html_attr("href"),\r\n    date = page %>%\r\n      html_elements(".image-left .date") %>%\r\n      # Dates are presented in a date-mont-year format, which is common in Germany.\r\n      # The locale must be installed on your computer, in this case "de_DE.UTF-8".\r\n      dmy(locale = "de_DE.UTF-8"),\r\n    raw = page %>%\r\n      html_elements(".image-left .listing-item") %>%\r\n      # You want to store this as `character` because a `tibble` does not accept a `xml_nodeset` item,\r\n      # which also points to a serialized object stored in memory.\r\n      # You can reserialze this object again using `read_html()`.\r\n      as.character()\r\n  )\r\n}\n'})}),"\n",(0,r.jsxs)(t.p,{children:["Using your just written function and the previously extracted last page number, a vector of all overview pages can now be created. Afterwards, using the function ",(0,r.jsx)(t.code,{children:"map()"})," from the package ",(0,r.jsx)(t.code,{children:"purrr"}),", your function can be applied to all pages and in turn and ",(0,r.jsx)(t.code,{children:"tibble"})," can be formed from them. (",(0,r.jsx)(t.code,{children:"map_dfr()"})," applies the function and forms a ",(0,r.jsx)(t.code,{children:"data.frame(df)"})," by merging the results row by row (r))."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'all_articles_summary <- read_rds("data/all_articles_summary.rds")\n'})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'url_part <- "https://www.anti-spiegel.ru/category/aktuelles/?dps_paged="\r\n\r\nall_page_urls <- map_chr(1:last_page_nmbr,\r\n                         ~paste0(url_part, .x))\r\n\r\nall_articles_summary <- map_dfr(all_page_urls, get_article_overview)\r\n\r\nall_articles_summary\r\n\n'})}),"\n",(0,r.jsxs)(t.p,{children:["Because ",(0,r.jsx)(t.code,{children:"R"})," and ",(0,r.jsx)(t.code,{children:"rvest"})," work only sequentially via ",(0,r.jsx)(t.code,{children:"map()"})," the command can often take a long time: one web page is called, scraped and then the next web page is called and scraped. The internet speed, the computing power as well as possible blockades by site operators can cause individual connections to get aborted, or the command would take so long that it is no longer practicable to scrape a web page."]}),"\n",(0,r.jsx)(t.p,{children:"You can improve the scraping process by parallelization: It is important to keep in mind that parallelization leads to additional load on the affected web servers. Several pages are opened in parallel \u2013 more in the chapter on parallelization."}),"\n",(0,r.jsx)(t.p,{children:"Webscraping is a gray area and is regulated differently from country to country or was part of court decisions. Even if site operators want to prevent web scraping, for example through their terms of use, it may still be justified and permitted, e.g. for consumer protection reasons. This is the case in Germany, for example (German Federal Court of Justice 2014)."}),"\n",(0,r.jsx)(t.h3,{id:"analyzing-scraped-data-and-next-steps",children:"Analyzing scraped data and next steps"}),"\n",(0,r.jsxs)(t.p,{children:["Since the data is in ",(0,r.jsx)(t.code,{children:"tidy"})," format (see ",(0,r.jsx)(t.a,{href:"http://www.jstatsoft.org/v59/i10/",children:"Wickham 2014"}),"), further analysis and presentation via the packages of the ",(0,r.jsx)(t.code,{children:"tidyverse"})," is simple and clear. Using ",(0,r.jsx)(t.code,{children:"ggplot"})," we can, for example, display the number of posts that were written per month."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'all_articles_summary %>%\r\n  mutate(month = floor_date(date, "month")) %>%\r\n  count(month) %>%\r\n  # It is recommended to filter out the current month\r\n  # because it risks being misrepresented in the dataset.\r\n  filter(month != today() %>% floor_date("month")) %>%\r\n  ggplot(aes(month, n)) +\r\n  geom_line() +\r\n  theme_light() +\r\n  labs(title = "Posts per Month on antispiegel.ru",\r\n       subtitle = glue("Posts until {today() %>% format(\'%B %Y\')}"),\r\n       y = "Posts", x = NULL)\n'})}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.img,{alt:"Number of article per month on the german pro-russion propaganda website antispiegel.ru by Thomas R\xf6per",src:n(3317).A+"",width:"1344",height:"960"}),"\r\n",(0,r.jsx)(t.em,{children:"Number of article per month on the german pro-russion propaganda website antispiegel.ru by Thomas R\xf6per"})]}),"\n",(0,r.jsxs)(t.p,{children:["The example of R\xf6per illustrates how to handle data from particularly active sites. While you didn\u2019t scrape the number of comments via your function, you can do so by extracting the number of comments from the raw values in the column ",(0,r.jsx)(t.code,{children:"raw"}),". Thus, you avoid further scraping of the data."]}),"\n",(0,r.jsxs)(t.p,{children:["Note that not all articles contain comments \u2013 if comments are missing, there is also no ",(0,r.jsx)(t.code,{children:"html_element"})," with comments, leading to fewer comment fields than e. g. title fields and a ",(0,r.jsx)(t.code,{children:"tibble"})," cannot be constructed."]}),"\n",(0,r.jsx)(t.admonition,{type:"hub-note",children:(0,r.jsx)(t.p,{children:"The reason why we did this is also because not all articles contain comments \u2013 if comments are missing, there is also no html_element with comments, leading to fewer comment fields then e. g. title fields and a tibble can\u2019t be constructed."})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'get_comments <- function(raw_data) {\r\n element <- read_html(raw_data)\r\n html_elements(element, ".comments-link a") %>% html_text(trim = TRUE)\r\n}\r\n\r\narticle_comments <- all_articles_summary %>%\r\n  # You should wrap this in \u201cpossibly\u201d to prevent errors from stopping the code execution.\r\n  # If you can\u2019t extract a comment string, you give it a NA value.\r\n  mutate(comments_string = map(raw,\r\n                               possibly(get_comments,\r\n                                        otherwise = NA_character_))) %>%\r\n  unnest(comments_string) %>%\r\n  mutate(comments = str_extract(comments_string, "\\\\d+") %>% as.numeric())\r\n\r\narticle_comments %>%\r\n  ggplot(aes(comments)) +\r\n  geom_histogram(binwidth = 1) +\r\n  theme_light() +\r\n  labs(title = "Histogram of comments at anti-spiegel.ru",\r\n       subtitle = glue("Posts until {today() %>% format(\'%B %Y\')}"))\n'})}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.img,{alt:"Histogram of number of comments under each article from anti-spiegel.ru",src:n(5966).A+"",width:"1344",height:"960"}),"\r\n",(0,r.jsx)(t.em,{children:"Histogram of number of comments under each article from anti-spiegel.ru"})]}),"\n",(0,r.jsxs)(t.p,{children:["As you can see, the most discussed article has 495 (",(0,r.jsx)(t.code,{children:"r article_comments %>% top_n(1, comments) %>% pull(comments)"}),') user comments with the headline "Putins Rede zur Vereinigung Russlands mit den ehemals ukrainischen Gebieten" (',(0,r.jsx)(t.code,{children:"r article_comments %>% top_n(1, comments) %>% pull(title)"}),") from 01. October 2022 (",(0,r.jsx)(t.code,{children:'r article_comments %>% top_n(1, comments) %>% pull(date) %>% format("%d. %B %Y")'}),"). Most of the articles are not commented."]}),"\n",(0,r.jsx)(t.h3,{id:"scraping-huge-datasets-via-parallelization",children:"Scraping huge datasets via parallelization"}),"\n",(0,r.jsx)(t.p,{children:"Previously, you learned how to scrape content sequentially and you were able to extract 20 article summaries per scraped page. If you now want to scrape not only the preview of the articles but all pages, the number of pages to be scrapped increases significantly."}),"\n",(0,r.jsxs)(t.p,{children:["With the package ",(0,r.jsx)(t.code,{children:"furrr"})," you can improve the scraping process by parallelization: It is important to keep in mind that parallelization leads to additional load on the affected web servers. Several pages are opened in parallel. It is therefore important to include pauses in the function definition to distribute the load and to keep the number of cores used for parallelization low - in this case a maximum of five workers working in parallel."]}),"\n",(0,r.jsxs)(t.p,{children:["Via ",(0,r.jsx)(t.code,{children:"plan(mulitsession)"})," you specify that the following code should be executed in parallel sessions - this is not always faster because the sessions must be started and ended. Small data sets are possibly better suited with a sequential approach."]}),"\n",(0,r.jsx)(t.p,{children:"All articles of Anti-Spiegel.ru should be scrapped and analyzed \u2013 however, in first tests it could be noticed that a lot of content on R\xf6per\u2019s page is repeated. For example, under each article there is a reference to his book published by J.K-Fischer Verlag. However, this advertisement for his own publication is separated from the rest of the text by a dividing line."}),"\n",(0,r.jsxs)(t.p,{children:["Using simple CSS selectors, however, this part cannot be separated from the rest -- though ",(0,r.jsx)(t.code,{children:"rvest"})," can be used with extended ",(0,r.jsx)(t.code,{children:"xpath"})," selectors. These allow us, for example, to only scrape ",(0,r.jsx)(t.code,{children:"<p>"})," nodes which are followed by a ",(0,r.jsx)(t.code,{children:"<hr>"})," node (the separator)."]}),"\n",(0,r.jsx)(t.admonition,{title:"Hint",type:"community",children:(0,r.jsxs)(t.p,{children:["Cheat sheets for using xpath selectors are available ",(0,r.jsx)(t.a,{href:"https://devhints.io/xpath",children:"here"}),"."]})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'\r\npage <- read_html("https://www.anti-spiegel.ru/2023/daenemark-deutschland-und-schweden-verweigern-auskunft-beim-un-sicherheitsrat-zur-nord-stream/")\r\n\r\npage %>%\r\n  html_elements(xpath = "//p[following-sibling::hr]") %>%\r\n  html_text() %>%\r\n  paste(collapse = "\\n")\r\n\n'})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:' [1] "UNO, 11. Juli. TASS/ Vertreter D\xe4nemarks, Deutschlands und Schwedens nehmen am Dienstag nicht an der von Russland einberufenen Sitzung des UN-Sicherheitsrates \xfcber die Sprengung der Gaspipelines Nord Stream und Nord Stream-2 teil, berichtet der TASS-Korrespondent.\\nZuvor hatte der erste stellvertretende st\xe4ndige Vertreter Russlands bei dem Weltgremium, Dmitri Poljanski, erkl\xe4rt, die russische Delegation habe f\xfcr den 11. Juli eine offene Sitzung des UN-Sicherheitsrates zum Thema der Spreungung der Nord-Stream-Pipeline beantragt. Dem Diplomaten zufolge hat Russland \u201edie britische Pr\xe4sidentschaft gebeten, Vertreter\u201c der drei L\xe4nder \u2013 D\xe4nemark, Deutschland und Schweden \u2013 einzuladen, die die Sabotage der Gaspipelines untersuchen, um dar\xfcber zu berichten."\n'})}),"\n",(0,r.jsxs)(t.p,{children:["Unfortunately, however, not all entries have this separator, so you won\u2019t get results for some entries with this ",(0,r.jsx)(t.code,{children:"xpath"})," selector \u2013 for example with this article."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'page <- read_html("https://www.anti-spiegel.ru/2022/ab-freitag-gibt-es-russisches-gas-nur-noch-fuer-rubel-die-details-von-putins-dekret-und-was-es-bedeutet/")\r\n\r\n\r\npage %>%\r\n  html_elements(xpath = "//p[following-sibling::hr]") %>%\r\n  html_text() %>%\r\n  paste(collapse = "\\n")\n'})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:' [1] ""\n'})}),"\n",(0,r.jsxs)(t.p,{children:["Often you will encounter such problems when webscraping, so it is important to work with a lot of examples first and test the code extensively. In this case, you scrape the data with a CSS selector and remove the always same advertising paragraphs with simple regular expressions. As mentioned above you create a function with pauses of 5 seconds (",(0,r.jsx)(t.code,{children:"Sys.sleep(5)"}),") on 5 processors at the same time."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'all_articles_full <- read_rds("data/all_articles_full.rds")\n'})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'library(furrr)\r\nplan(multisession, workers = 5)\r\n\r\nget_article_data <- function(url) {\r\n  page <- read_html(url)\r\n\r\n  # Pause for 5 seconds\r\n  Sys.sleep(5)\r\n\r\n  # regex for addendum beginning\r\n  pattern_addendum <- "In meinem neuen Buch.*$|Das Buch ist aktuell erschienen.*$"\r\n\r\n  tibble(\r\n    url = url,\r\n    raw = page %>%\r\n      html_elements(".article__content > p") %>%\r\n      # `html_text2` to trim the data and remove unnecessary white spaces.\r\n      as.character() %>%\r\n      str_remove(pattern_addendum) %>%\r\n      paste0(collapse = ""),\r\n    text = page %>%\r\n      html_elements(".article__content > p") %>%\r\n      html_text() %>%\r\n      str_remove(pattern_addendum) %>%\r\n      paste(collapse = "\\n"),\r\n    datetime = page %>%\r\n      html_elements(".article-meta__date-time") %>%\r\n      html_text2() %>% # <1>\r\n      dmy_hm(locale = "de_DE.UTF-8")\r\n  )\r\n\r\n}\r\n\r\nall_articles_full <- future_map(all_articles_summary %>%\r\n                                  filter(date >= "2022-01-01") %>% pull(url),\r\n                                  # Wrapped in `try` to prevent errors from failing the whole process \u2013\r\n                                  # failed scrapings can be removed afterwards.\r\n                                  ~try(get_article_data(.x)), .progress = TRUE)\n'})}),"\n",(0,r.jsx)(t.p,{children:"Next, you will implement further measures to prevent your code from breaking prematurely and losing the already scraped content. Since the idea is that you wrap the function in a try, even errors do not lead to an abortion of the scraping. Errors can, however, mean connection failures. These failures can be fixed in a further process \u2013 if errors occur too often, it is recommended to optimize the code or to have longer pause times during the scraping to avoid overloading the servers."}),"\n",(0,r.jsx)(t.p,{children:"To avoid scraping all websites, you should set clear limits for data collection, in this example this will be data from 2022 onwards \u2013 in a final step, you want to determine which domains are particularly frequently cited by Thomas R\xf6per."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'all_articles_df <- all_articles_full %>%\r\n  keep(is_tibble) %>%\r\n  bind_rows()\r\n\r\nget_links <- function(raw_html) {\r\n  element <- read_html(raw_html)\r\n  element %>% html_elements("a") %>% html_attr("href")\r\n}\r\n\r\nget_domain <- function(link) {\r\n  # regex for domain\r\n  domain_pattern <- "^(?:[^@\\\\/\\\\n]+@)?([^:\\\\/?\\\\n]+)"\r\n\r\n  link %>%\r\n    str_remove("http://|https://") %>%\r\n    str_remove("^www.") %>%\r\n    str_extract(domain_pattern)\r\n}\r\n\r\nall_articles_df %>%\r\n  mutate(links = map(raw, possibly(get_links, otherwise = NA_character_))) %>%\r\n  mutate(domain = map(links, possibly(get_domain, otherwise = NA_character_))) %>%\r\n  unnest(domain) %>%\r\n  count(domain, sort = TRUE) %>%\r\n  head(10) %>%\r\n  # `kable()` from the library `knitr` is only used in this context to generate an html table\r\n  knitr::kable() # <1>\n'})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.em,{children:"Table 1: Most shared domains by anti-spiegel.ru"})}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"domain"}),(0,r.jsx)(t.th,{children:"n"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"anti-spiegel.ru"}),(0,r.jsx)(t.td,{children:"5793"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"tass.ru"}),(0,r.jsx)(t.td,{children:"1219"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"spiegel.de"}),(0,r.jsx)(t.td,{children:"611"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"vesti7.ru"}),(0,r.jsx)(t.td,{children:"303"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"t.me"}),(0,r.jsx)(t.td,{children:"245"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"vesti.ru"}),(0,r.jsx)(t.td,{children:"191"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"deutsch.rt.com"}),(0,r.jsx)(t.td,{children:"137"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"youtube.com"}),(0,r.jsx)(t.td,{children:"126"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"kremlin.ru"}),(0,r.jsx)(t.td,{children:"85"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"mid.ru"}),(0,r.jsx)(t.td,{children:"82"})]})]})]}),"\n",(0,r.jsxs)(t.p,{children:["To sum up, your first webscraping case highlighted that R\xf6per refers particularly frequently to the Russian news agency TASS and the Kremlin outlet RT DE. From a research perspective, it is noteworthy that there are European sanctions and a broadcast ban against RT DE (see ",(0,r.jsx)(t.a,{href:"https://www.spiegel.de/kultur/ukraine-krieg-verbreitung-von-rt-und-sputnik-ist-in-der-eu-ab-sofort-verboten-a-49597add-c2b2-44da-b1e4-6832d3ea824f",children:"Spiegel 2022"}),"; ",(0,r.jsx)(t.a,{href:"https://www.derstandard.de/story/2000133980411/bis-50-000-euro-fuer-verbreitung-von-russischem-staatssender-rt",children:"Der Standard 2022"}),") \u2013 yet our test case continues to share them (for possible explanations why, see ",(0,r.jsx)(t.a,{href:"https://correctiv.org/aktuelles/russland-ukraine-2/2023/02/17/eu-sanktionen-gcore-russia-today/",children:"Baeck et al. 2023"}),"). Among the most shared domains is also t.me of the platform and messenger service Telegram \u2013 this platform is used by R\xf6per particularly often, along with YouTube. Incidentally, if you hadn\u2019t removed the advertising block, J.K. Fischer Verlag would rank first in this table."]}),"\n",(0,r.jsx)(t.h3,{id:"second-example-auf1-as-a-dynamic-website",children:"Second example: AUF1 as a dynamic website"}),"\n",(0,r.jsx)(t.p,{children:"R\xf6per\u2019s website is comparatively simple in design. The Wordpress site is statically generated. The web server simply outputs HTML pages, which can be downloaded and checked."}),"\n",(0,r.jsxs)(t.p,{children:["Not all sites are built this way, in fact it has probably become more common to host ",(0,r.jsx)(t.strong,{children:"dynamic websites"}),". This is also the case with the Austrian website AUF1 of the right-wing extremist and conspiracy ideologue Stefan Magnet (see ",(0,r.jsx)(t.a,{href:"https://correctiv.org/faktencheck/hintergrund/2023/04/27/was-hinter-auf1-stefan-magnet-und-der-ausbreitung-des-oesterreichischen-verschwoerungssenders-steckt-desinformation-und-rechte-hetze/",children:"Scherndl and Thom 2023"}),"), which quickly became one of the most widespread websites of pandemic deniers in the German-speaking world from autumn 2021."]}),"\n",(0,r.jsxs)(t.p,{children:["Content scraped via ",(0,r.jsx)(t.code,{children:"rvest"})," shows that reactions cannot be scraped \u2013 it simply shows an empty value."]}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.img,{alt:"AUF1 Screenshot with Reactions",src:n(4500).A+"",width:"1293",height:"961"}),"\r\n",(0,r.jsx)(t.em,{children:"AUF1 Screenshot with Reactions"})]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'rndm_article <- "https://auf1.tv/auf1-spezial/fpoe-gesundheitssprecher-kaniak-zu-who-plaenen-impf-zwang-auch-ohne-pandemie"\r\n\r\npage <- read_html(rndm_article)\r\n\r\npage %>% html_elements(".reactions")\n'})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"{xml_nodeset (0)}\n"})}),"\n",(0,r.jsxs)(t.p,{children:["A workaround here is to simulate a browser, which calls the page and executes all content. One possibility for this would be to use ",(0,r.jsx)(t.code,{children:"Selenium"}),". This is a framework for automated software testing of web applications in different browsers \u2013and you can use it for advanced web scraping, too."]}),"\n",(0,r.jsxs)(t.p,{children:["With ",(0,r.jsx)(t.code,{children:"RSelenium"})," you can start different browsers (to replicate this example, you should use Firefox, the corresponding binaries are downloaded via ",(0,r.jsx)(t.code,{children:"wdman"}),"). Afterwards you navigate to the corresponding page and then load the web page contents of the finished page back into rvest via read_html. Then, you can work as before and analyze different contents."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:'#| label: tbl-emojis\r\n#| tbl-cap: Reactions used on a random AUF1 article\r\nlibrary(RSelenium)\r\n\r\n# start the browser\r\n# check if java and openjdk is installed first\r\n# wdman will install the rest\r\nrD <- rsDriver(browser = "firefox", verbose = FALSE)\r\nrD$client$navigate(rndm_article)\r\n\r\n# Setting a _sleep_ for 3 seconds to guarantee that the page has finished loading.\r\nSys.sleep(3)\r\n\r\n# We can load in the Selenium page source directly into rvest and use it as before\r\npage <- read_html(rD$client$getPageSource()[[1]])\r\n\r\ntibble(\r\n  emoji = page %>%\r\n    html_elements(".reactions .emoji") %>%\r\n    html_text() %>%\r\n    unique(),\r\n  count = page %>%\r\n    html_elements(".reactions .count") %>%\r\n    html_text() %>%\r\n    as.integer()\r\n  ) %>%\r\n  arrange(-count) %>%\r\n  pivot_wider(names_from = emoji, values_from = count) %>%\r\n  # Just for styling purposes, this looks more clean in the browser\r\n  knitr::kable(align = "c")\r\n\r\n\n'})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.em,{children:"Table 2: Reactions used on a random AUF1 article"})}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"\ud83d\udc4d\ud83c\udffb"}),(0,r.jsx)(t.th,{children:"\u2764\ufe0f"}),(0,r.jsx)(t.th,{children:"\ud83d\udcaa\ud83c\udffb"}),(0,r.jsx)(t.th,{children:"\ud83d\ude2e"}),(0,r.jsx)(t.th,{children:"\ud83d\ude22"})]})}),(0,r.jsx)(t.tbody,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"489"}),(0,r.jsx)(t.td,{children:"229"}),(0,r.jsx)(t.td,{children:"131"}),(0,r.jsx)(t.td,{children:"64"}),(0,r.jsx)(t.td,{children:"58"})]})})]}),"\n",(0,r.jsxs)(t.p,{children:["With ",(0,r.jsx)(t.code,{children:"RSelenium"})," you can extract data which wouldn\u2019t be possible via ",(0,r.jsx)(t.code,{children:"rvest"})," alone. You could now write a function to extract all emojis on videos and find the video that had the most interactions \u2013 this is not something, we will show in this chapter, but should be provided for interested (social) scientists and civil society researchers to build webscraping projects on their own. Even for advanced and dynamic web pages."]}),"\n",(0,r.jsx)(t.p,{children:"One last thing: Since you are using an automated browser on Desktop, you need to close it after reading in your data. Otherwise, the browser will keep on running in the background. You should also close your server that provided the background tasks for running Selenium."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-r",children:"rD$client$close()\r\nrD$server$stop()\n"})}),"\n",(0,r.jsx)(t.h2,{id:"literature",children:"Literature"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["AlgorithmWatch. (2023). DSA Must Empower Public Interest Research with Public Data Access. AlgorithmWatch. ",(0,r.jsx)(t.a,{href:"https://algorithmwatch.org/en/dsa-empower-public-interest-research-data-access/",children:"https://algorithmwatch.org/en/dsa-empower-public-interest-research-data-access/"})]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["Baeck, Jean-Philipp, Fromm, Anne, & Peters, Jean. (2023). Warum Russia Today trotz Sanktionen in Europa weiterl\xe4uft. correctiv.org. ",(0,r.jsx)(t.a,{href:"https://correctiv.org/aktuelles/russland-ukraine-2/2023/02/17/eu-sanktionen-gcore-russia-today/",children:"https://correctiv.org/aktuelles/russland-ukraine-2/2023/02/17/eu-sanktionen-gcore-russia-today/"})]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["Balzer, Erika. (2022). Desinformations-Medien: Der Anti-Spiegel - Russische Propaganda und Verschw\xf6rungsmythen. Belltower.News. ",(0,r.jsx)(t.a,{href:"https://www.belltower.news/desinformations-medien-der-anti-spiegel-russische-propaganda-und-verschwoerungsmythen-132357/",children:"https://www.belltower.news/desinformations-medien-der-anti-spiegel-russische-propaganda-und-verschwoerungsmythen-132357/"})]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["Binder, Matt. (2023). Elon Musk Claims Twitter Login Requirement Just 'Temporary'. Mashable. ",(0,r.jsx)(t.a,{href:"https://mashable.com/article/elon-musk-twitter-login-requirement-temporary",children:"https://mashable.com/article/elon-musk-twitter-login-requirement-temporary"})]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["DerStandard. (2022). Bis zu 50.000 Euro Strafe f\xfcr Verbreitung von russischem Staatssender RT \u2013 alleine FP\xd6 stimmt dagegen. DER STANDARD. ",(0,r.jsx)(t.a,{href:"https://www.derstandard.de/story/2000133980411/bis-50-000-euro-fuer-verbreitung-von-russischem-staatssender-rt",children:"https://www.derstandard.de/story/2000133980411/bis-50-000-euro-fuer-verbreitung-von-russischem-staatssender-rt"})]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["EDMO. (2023). Members of the EDMO Task Force on Disinformation on the War in Ukraine Submit Feedback to the EC Call for Evidence on the Provisions in the DSA Related to Data Access. EDMO. ",(0,r.jsx)(t.a,{href:"https://edmo.eu/2023/05/30/members-of-the-edmo-task-force-on-disinformation-on-the-war-in-ukraine-submit-feedback-to-the-ec-call-for-evidence-on-the-provisions-in-the-dsa-related-to-data-access/",children:"https://edmo.eu/2023/05/30/members-of-the-edmo-task-force-on-disinformation-on-the-war-in-ukraine-submit-feedback-to-the-ec-call-for-evidence-on-the-provisions-in-the-dsa-related-to-data-access/"})]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["Fung, Brian. (2023a). Academic Researchers Blast Twitter's Data Paywall as 'outrageously Expensive'. CNN Business. ",(0,r.jsx)(t.a,{href:"https://www.cnn.com/2023/04/05/tech/academic-researchers-blast-twitter-paywall/index.html",children:"https://www.cnn.com/2023/04/05/tech/academic-researchers-blast-twitter-paywall/index.html"})]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["Fung, Brian. (2023b). Reddit Sparks Outrage after a Popular App Developer Said It Wants Him to Pay $20 Million a Year for Data Access. CNN Business. ",(0,r.jsx)(t.a,{href:"https://www.cnn.com/2023/06/01/tech/reddit-outrage-data-access-charge/index.html",children:"https://www.cnn.com/2023/06/01/tech/reddit-outrage-data-access-charge/index.html"})]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:"German Federal Court of Justice. (2014). BGH, 30.04.2014 - I ZR 224/12. BGH."}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["Glez-Pe\xf1a, Daniel, Louren\xe7o, An\xe1lia, L\xf3pez-Fern\xe1ndez, Hugo, Reboiro-Jato, Miguel, & Fdez-Riverola, Florentino. (2014). Web Scraping Technologies in an API World. Briefings in Bioinformatics. ",(0,r.jsx)(t.a,{href:"https://academic.oup.com/bib/article-lookup/doi/10.1093/bib/bbt026",children:"https://academic.oup.com/bib/article-lookup/doi/10.1093/bib/bbt026"})]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["Journalist. (2022). Im Desinformationskrieg. journalist.de. ",(0,r.jsx)(t.a,{href:"https://www.journalist.de/startseite/detail/article/im-desinformationskrieg",children:"https://www.journalist.de/startseite/detail/article/im-desinformationskrieg"})]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:"Khder, Moaiad Ahmad. (2021). Web Scraping or Web Crawling: State of Art, Techniques, Approaches and Application. International Journal of Advances in Soft Computing & Its Applications, 13(3)."}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["Scherndl, Gabriele, & Thom, Paulina. (2023). Was hinter dem \xf6sterreichischen Verschw\xf6rungssender Auf1 steckt. correctiv.org. ",(0,r.jsx)(t.a,{href:"https://correctiv.org/faktencheck/hintergrund/2023/04/27/was-hinter-auf1-stefan-magnet-und-der-ausbreitung-des-oesterreichischen-verschwoerungssenders-steckt-desinformation-und-rechte-hetze/",children:"https://correctiv.org/faktencheck/hintergrund/2023/04/27/was-hinter-auf1-stefan-magnet-und-der-ausbreitung-des-oesterreichischen-verschwoerungssenders-steckt-desinformation-und-rechte-hetze/"})]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["Spiegel. (2022). Ma\xdfnahmen gegen russische Staatsmedien: Verbreitung von RT und Sputnik ist in der EU ab sofort verboten. Der Spiegel. ",(0,r.jsx)(t.a,{href:"https://www.spiegel.de/kultur/ukraine-krieg-verbreitung-von-rt-und-sputnik-ist-in-der-eu-ab-sofort-verboten-a-49597add-c2b2-44da-b1e4-6832d3ea824f",children:"https://www.spiegel.de/kultur/ukraine-krieg-verbreitung-von-rt-und-sputnik-ist-in-der-eu-ab-sofort-verboten-a-49597add-c2b2-44da-b1e4-6832d3ea824f"})]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["Wickham, Hadley. (2014). Tidy Data. The Journal of Statistical Software. ",(0,r.jsx)(t.a,{href:"http://www.jstatsoft.org/v59/i10/",children:"http://www.jstatsoft.org/v59/i10/"})]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}function p(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},465:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/holnburger-035792ed8aad4144d9fc8cd16194e76b.png"},4500:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/AUF1_reactions-95bc1af657675ffd9a00a2e1f0589e68.png"},3317:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/plot_1-98776c7017436679523fdebd847ca042.png"},5966:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/plot_2-ec60d79e0fbbceb979c5301a4f02b65a.png"},6017:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/roeper_next_page-bd23fa15b5cb841083b37b22faaad0dc.png"},8962:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/roeper_page_example-2b590efa2f77414771045b30e851cdf1.png"}}]);